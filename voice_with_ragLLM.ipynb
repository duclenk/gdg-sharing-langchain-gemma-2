{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-speech in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (2.28.1)\n",
      "Requirement already satisfied: pyaudio in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (0.2.14)\n",
      "Collecting google-cloud-texttospeech\n",
      "  Downloading google_cloud_texttospeech-2.21.1-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.23.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-cloud-speech) (2.36.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-cloud-speech) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-cloud-speech) (5.28.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.68.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/birutekno/miniconda3/envs/telin/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2024.8.30)\n",
      "Downloading google_cloud_texttospeech-2.21.1-py2.py3-none-any.whl (170 kB)\n",
      "Installing collected packages: google-cloud-texttospeech\n",
      "Successfully installed google-cloud-texttospeech-2.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-speech pyaudio google-cloud-texttospeech\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THIS FUNCTION IS TO LOAD VECTOR STORE THAT WE CREATE BEFORE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ng92lp3ynw3p3o-11434.proxy.runpod.net\n",
      "------[LOG]------\n",
      " /Users/birutekno/Documents/Project/soca-ml-app/materi-gdg/vectoring/embeddings \n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from pydub import AudioSegment\n",
    "import warnings\n",
    "\n",
    "from pydub.playback import play\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
    "\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")\n",
    "print(config['IP_OLLAMA'])\n",
    "def load_models(data_path):\n",
    "    if os.path.exists(data_path):\n",
    "        print(\"------[LOG]------\\n\", data_path, \"\\n-----------------\")\n",
    "        vector_store = FAISS.load_local(\n",
    "            data_path,\n",
    "            OllamaEmbeddings(model=\"bge-m3\", base_url=config['IP_OLLAMA']),\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        return vector_store\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Data path does not exist: {data_path}\")\n",
    "    \n",
    "retrievers = load_models(\"/Users/birutekno/Documents/Project/soca-ml-app/materi-gdg/vectoring/embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is function for handling RAG With Gemma 2 LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema.runnable import RunnableMap, RunnableLambda\n",
    "\n",
    "def running_rag():\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"kamu adalah bot pintar menggunakan gemma2, jawab pertanyaan user hanya berdasarkan context yang diberikan. \n",
    "        selalu jawab pertanyaan user menggunakan bahasa indonesia dan beri penjelasan yang komperhensif secara singkat namun mudah di mengerti. jika kamu tidak tahu jawabannya, sebutkan saja \n",
    "        \"maaf saya tidak tahu\", jangan coba untuk memberikan jawaban yang tidak relevan.\n",
    "\n",
    "        Context: {context}\\n\n",
    "        Question: {question}\\n\n",
    "        Answer:\"\"\"\n",
    "    )\n",
    "\n",
    "    ollama_model = \"gemma2:latest\"\n",
    "    api_url = config[\"IP_OLLAMA\"]\n",
    "\n",
    "    llm = ChatOllama(\n",
    "        model=ollama_model,\n",
    "        base_url=api_url, temperature=0.3\n",
    "    )\n",
    "\n",
    "    retriever = retrievers.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 4}\n",
    "    )\n",
    "\n",
    "    def debug_documents(inputs):\n",
    "        docs = inputs.get(\"documents\", [])\n",
    "        for doc in docs:\n",
    "            print(f\"[DEBUG] Chunk to LLM: {doc.page_content}\")\n",
    "        return inputs\n",
    "\n",
    "    pipeline = RunnableMap({\n",
    "        \"retriever\": RunnableLambda(lambda inputs: {\"documents\": retriever.get_relevant_documents(inputs[\"question\"])}),\n",
    "        \"debugger\": RunnableLambda(debug_documents),\n",
    "        \"qa_chain\": RetrievalQAWithSourcesChain.from_chain_type(\n",
    "            llm=llm,\n",
    "            retriever=retriever,\n",
    "            chain_type=\"stuff\",\n",
    "            chain_type_kwargs={\"prompt\": prompt_template, \"document_variable_name\": \"context\"},\n",
    "            return_source_documents=True,\n",
    "            verbose=True\n",
    "        ),\n",
    "    })\n",
    "    return pipeline\n",
    "\n",
    "def invoke_rag(question):\n",
    "    print(\"this is question\", question)\n",
    "    pipeline = running_rag()\n",
    "    result = pipeline.invoke({\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "    answer = result[\"qa_chain\"][\"answer\"]\n",
    "    source_list = [\n",
    "        str(doc.metadata[\"source\"]).split(\"/\")[-1]\n",
    "        for doc in result[\"qa_chain\"][\"source_documents\"]\n",
    "        if str(doc.metadata[\"source\"]).split(\".\")[-1] not in [\"jpg\", \"png\"]\n",
    "    ]\n",
    "    source_list = list(set(source_list))\n",
    "    print(\"souce list\", source_list)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import speech_v1p1beta1 as speech\n",
    "import os\n",
    "from dotenv import dotenv_values\n",
    "import io\n",
    "config = dotenv_values(\".env\")\n",
    "credential_keys = config['CREDENTIAL_PATH']\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=credential_keys\n",
    "from google.cloud import speech_v1 as speech\n",
    "from google.cloud import speech, texttospeech\n",
    "\n",
    "import io\n",
    "\n",
    "def transcribe_audio(audio_file_path):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(audio_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"id-ID\", \n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.recognize(config=config, audio=audio)\n",
    "        print(response)\n",
    "        if not response.results:\n",
    "            return \"No transcription results. Ensure audio clarity and configuration correctness.\"\n",
    "\n",
    "        transcript = \" \".join(result.alternatives[0].transcript for result in response.results)\n",
    "        return transcript\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during transcription: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def post_tts(text, emotion='normal', pitch=1, gender=\"Female\", language_code=\"id-ID\", ssml_name=\"id-ID-Wavenet-B\"):\n",
    "    \"\"\"Generates a TTS audio from the input text.\"\"\"\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "    ssml_gender = texttospeech.SsmlVoiceGender.FEMALE if gender != \"Male\" else texttospeech.SsmlVoiceGender.MALE\n",
    "    speaking_rate = 1\n",
    "    pitch = int(pitch)\n",
    "    volume_gain_db = 0\n",
    "    if emotion.lower() == \"excited\":\n",
    "        speaking_rate = 1.1\n",
    "        pitch = 5.0\n",
    "        volume_gain_db = 6.0\n",
    "\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=language_code,\n",
    "        name=ssml_name,\n",
    "        ssml_gender=ssml_gender,\n",
    "    )\n",
    "\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3,\n",
    "        speaking_rate=speaking_rate,\n",
    "        pitch=pitch,\n",
    "        volume_gain_db=volume_gain_db,\n",
    "    )\n",
    "\n",
    "    response = client.synthesize_speech(\n",
    "        request={\"input\": input_text, \"voice\": voice, \"audio_config\": audio_config}\n",
    "    )\n",
    "\n",
    "    return response.audio_content\n",
    "\n",
    "def play_audio(content,filename=\"response_audio.mp3\"):\n",
    "    \"\"\"Plays audio content using pydub.\"\"\"\n",
    "    if not content:\n",
    "        raise ValueError(\"Audio content is empty or invalid.\")\n",
    "    with open(filename, 'wb') as audio_file:\n",
    "        audio_file.write(content)\n",
    "    audio = AudioSegment.from_file(filename, format=\"mp3\")\n",
    "    play(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into the microphone...\n",
      "this is question Siapa nama Menteri Keuangan saat ini\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/_5r061fs01dfpsm_ydkg8_f00000gn/T/ipykernel_61605/1267120307.py:37: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  \"retriever\": RunnableLambda(lambda inputs: {\"documents\": retriever.get_relevant_documents(inputs[\"question\"])}),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "souce list ['nama_mentri.pdf']\n",
      "answer Nama Menteri Keuangan saat ini adalah Sri Mulyani Indrawati. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732897110.458835 1502679 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1732897110.617864 1502679 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import speech\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credential_keys\n",
    "\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)\n",
    "\n",
    "class MicrophoneStream:\n",
    "    def __init__(self, rate, chunk):\n",
    "        self.rate = rate\n",
    "        self.chunk = chunk\n",
    "\n",
    "        self.buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.audio_interface = pyaudio.PyAudio()\n",
    "        self.audio_stream = self.audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self.rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk,\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.audio_stream.stop_stream()\n",
    "        self.audio_stream.close()\n",
    "        self.closed = True\n",
    "        self.buff.put(None)\n",
    "        self.audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        self.buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            chunk = self.buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self.buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "            yield b\"\".join(data)\n",
    "\n",
    "\n",
    "def listen_and_transcribe():\n",
    "    \"\"\"Streams microphone input to Google Speech-to-Text for transcription.\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=\"id-ID\"\n",
    "    )\n",
    "    streaming_config = speech.StreamingRecognitionConfig(config=config, interim_results=True)\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (speech.StreamingRecognizeRequest(audio_content=content) for content in audio_generator)\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        for response in responses:\n",
    "            for result in response.results:\n",
    "                if result.is_final:\n",
    "                    result_speech = result.alternatives[0].transcript.strip()\n",
    "                    if result_speech.lower() in [\"terima kasih\", \"terimakasih\"] :\n",
    "                        print(\"Detected keyword for stopping\")\n",
    "                        return  \n",
    "                    answers = invoke_rag(result_speech)\n",
    "                    print(\"answer\", answers)\n",
    "                    tts_response = post_tts(answers)\n",
    "                    # print(\"this is response\",tts_response)\n",
    "                    play_audio(tts_response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Speak into the microphone...\")\n",
    "    listen_and_transcribe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"/Users/birutekno/Documents/Project/soca-ml-app/materi-gdg/response_audio.mp3\"\n",
    "if not os.path.exists(file_path):\n",
    "    print(\"File does not exist!\")\n",
    "else:\n",
    "    print(\"File exists!\")\n",
    "\n",
    "audio = AudioSegment.from_file(\"/Users/birutekno/Documents/Project/soca-ml-app/materi-gdg/response_audio.mp3\", format=\"mp3\")\n",
    "play(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
